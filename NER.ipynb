{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamronsuez/nlp-notebooks/blob/main/NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTP3w5RryZLi"
      },
      "source": [
        "**Universidad Internacional de La Rioja (UNIR) - Máster Universitario en Inteligencia Artificial - Procesamiento del Lenguaje Natural**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC345QBJyZLj"
      },
      "source": [
        "***\n",
        "Datos del alumno (Nombre y Apellidos): Ronald Suez\n",
        "\n",
        "Fecha: 28/04/2024\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md1lPaz8yZLk"
      },
      "source": [
        "<span style=\"font-size: 20pt; font-weight: bold; color: #0098cd;\">Trabajo: Named-Entity Recognition</span>\n",
        "\n",
        "**Objetivos**\n",
        "\n",
        "Con esta actividad se tratará de que el alumno se familiarice con el manejo de la librería spacy, así como con los conceptos básicos de manejo de las técnicas NER\n",
        "\n",
        "**Descripción**\n",
        "\n",
        "En esta actividad debes procesar de forma automática un texto en lenguaje natural para detectar características básicas en el mismo, y para identificar y etiquetar las ocurrencias de conceptos como localización, moneda, empresas, etc.\n",
        "\n",
        "En la primera parte del ejercicio se proporciona un código fuente a través del cual se lee un archivo de texto y se realiza un preprocesado del mismo. En esta parte el alumno tan sólo debe ejecutar y entender el código proporcionado.\n",
        "\n",
        "En la segunda parte del ejercicio se plantean una serie de preguntas que deben ser respondidas por el alumno. Cada pregunta deberá responderse con un fragmento de código fuente que esté acompañado de la explicación correspondiente. Para elaborar el código solicitado, el alumno deberá visitar la documentación de la librería spacy, cuyos enlaces se proporcionarán donde corresponda."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hXVynM2yZLk"
      },
      "source": [
        "# Parte 1: carga y preprocesamiento del texto a analizar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKIEVb-TyZLk"
      },
      "source": [
        "Observa las diferentes librerías que se están importando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddJyXm5PyZLl"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "import en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnJwwDqWx9AS",
        "outputId": "8644e251-ae24-4483-da1b-5a01c5d2b4bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPyGHmBqyZLm"
      },
      "source": [
        "El siguiente código simplemente carga y preprocesa el texto. Para ello, lo primero que hace es cargar un modelo de lenguaje previamente entrenado. En este caso, se utiliza <i>en_core_web_sm</i>:\n",
        "\n",
        "https://spacy.io/models/en#en_core_web_sm\n",
        "\n",
        "Al cargar el modelo de lenguaje se genera un <i>Pipeline</i>, que nos permite realizar las diferentes tareas. En este caso, vamos a utilizar el pipeline para hacer un preprocesamiento básico, que consiste en tokenizar el texto.\n",
        "\n",
        "Al final del código proporcionado <i>doc</i> representa una versión tokenizada del texto leído."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "glFUDAWKyZLm"
      },
      "outputs": [],
      "source": [
        "nlp = en_core_web_sm.load()\n",
        "file_name = \"/content/drive/MyDrive/Colab Notebooks/barack-obama-speech.txt\"\n",
        "doc = nlp(pathlib.Path(file_name).read_text(encoding=\"utf-8\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nt2EObp3z0Ie",
        "outputId": "fd95b66f-69c0-4b62-ff51-6c39ec8f8eea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "“Hello, Chicago.\n",
              "If there is anyone out there who still doubts that America is a place where all things are possible, who still wonders if the dream of our founders is alive in our time, who still questions the power of our democracy, tonight is your answer.\n",
              "It’s the answer told by lines that stretched around schools and churches in numbers this nation has never seen, by people who waited three hours and four hours, many for the first time in their lives, because they believed that this time must be different, that their voices could be that difference.\n",
              "It’s the answer spoken by young and old, rich and poor, Democrat and Republican, black, white, Hispanic, Asian, Native American, gay, straight, disabled and not disabled. Americans who sent a message to the world that we have never been just a collection of individuals or a collection of red states and blue states.\n",
              "We are, and always will be, the United States of America.\n",
              "It’s the answer that led those who’ve been told for so long by so many to be cynical and fearful and doubtful about what we can achieve to put their hands on the arc of history and bend it once more toward the hope of a better day.\n",
              "It’s been a long time coming, but tonight, because of what we did on this date in this election at this defining moment change has come to America.\n",
              "[read more]\n",
              "\n",
              "We didn’t start with much money or many endorsements. Our campaign was not hatched in the halls of Washington. It began in the backyards of Des Moines and the living rooms of Concord and the front porches of Charleston. It was built by working men and women who dug into what little savings they had to give $5 and $10 and $20 to the cause.\n",
              "It grew strength from the young people who rejected the myth of their generation’s apathy who left their homes and their families for jobs that offered little pay and less sleep.\n",
              "It drew strength from the not-so-young people who braved the bitter cold and scorching heat to knock on doors of perfect strangers, and from the millions of Americans who volunteered and organized and proved that more than two centuries later a government of the people, by the people, and for the people has not perished from the Earth.\n",
              "This is your victory.\n",
              "And I know you didn’t do this just to win an election. And I know you didn’t do it for me.\n",
              "You did it because you understand the enormity of the task that lies ahead. For even as we celebrate tonight, we know the challenges that tomorrow will bring are the greatest of our lifetime — two wars, a planet in peril, the worst financial crisis in a century.\n",
              "Even as we stand here tonight, we know there are brave Americans waking up in the deserts of Iraq and the mountains of Afghanistan to risk their lives for us.\n",
              "There are mothers and fathers who will lie awake after the children fall asleep and wonder how they’ll make the mortgage or pay their doctors’ bills or save enough for their child’s college education.\n",
              "There’s new energy to harness, new jobs to be created, new schools to build, and threats to meet, alliances to repair.\n",
              "The road ahead will be long. Our climb will be steep. We may not get there in one year or even in one term. But, America, I have never been more hopeful than I am tonight that we will get there.\n",
              "I promise you, we as a people will get there.\n",
              "There will be setbacks and false starts. There are many who won’t agree with every decision or policy I make as president. And we know the government can’t solve every problem.\n",
              "But I will always be honest with you about the challenges we face. I will listen to you, especially when we disagree. And, above all, I will ask you to join in the work of remaking this nation, the only way it’s been done in America for 221 years — block by block, brick by brick, calloused hand by calloused hand.\n",
              "What began 21 months ago in the depths of winter cannot end on this autumn night.\n",
              "This victory alone is not the change we seek. It is only the chance for us to make that change. And that cannot happen if we go back to the way things were.\n",
              "It can’t happen without you, without a new spirit of service, a new spirit of sacrifice.\n",
              "So let us summon a new spirit of patriotism, of responsibility, where each of us resolves to pitch in and work harder and look after not only ourselves but each other.\n",
              "Let us remember that, if this financial crisis taught us anything, it’s that we cannot have a thriving Wall Street while Main Street suffers.\n",
              "In this country, we rise or fall as one nation, as one people. Let’s resist the temptation to fall back on the same partisanship and pettiness and immaturity that has poisoned our politics for so long.\n",
              "Let’s remember that it was a man from this state who first carried the banner of the Republican Party to the White House, a party founded on the values of self-reliance and individual liberty and national unity.\n",
              "Those are values that we all share. And while the Democratic Party has won a great victory tonight, we do so with a measure of humility and determination to heal the divides that have held back our progress.\n",
              "As Lincoln said to a nation far more divided than ours, we are not enemies but friends. Though passion may have strained, it must not break our bonds of affection.\n",
              "And to those Americans whose support I have yet to earn, I may not have won your vote tonight, but I hear your voices. I need your help. And I will be your president, too.\n",
              "And to all those watching tonight from beyond our shores, from parliaments and palaces, to those who are huddled around radios in the forgotten corners of the world, our stories are singular, but our destiny is shared, and a new dawn of American leadership is at hand.\n",
              "To those — to those who would tear the world down: We will defeat you. To those who seek peace and security: We support you. And to all those who have wondered if America’s beacon still burns as bright: Tonight we proved once more that the true strength of our nation comes not from the might of our arms or the scale of our wealth, but from the enduring power of our ideals: democracy, liberty, opportunity and unyielding hope.\n",
              "That’s the true genius of America: that America can change. Our union can be perfected. What we’ve already achieved gives us hope for what we can and must achieve tomorrow.\n",
              "This election had many firsts and many stories that will be told for generations. But one that’s on my mind tonight’s about a woman who cast her ballot in Atlanta. She’s a lot like the millions of others who stood in line to make their voice heard in this election except for one thing: Ann Nixon Cooper is 106 years old.\n",
              "She was born just a generation past slavery; a time when there were no cars on the road or planes in the sky; when someone like her couldn’t vote for two reasons — because she was a woman and because of the color of her skin.\n",
              "And tonight, I think about all that she’s seen throughout her century in America — the heartache and the hope; the struggle and the progress; the times we were told that we can’t, and the people who pressed on with that American creed: Yes we can.\n",
              "At a time when women’s voices were silenced and their hopes dismissed, she lived to see them stand up and speak out and reach for the ballot. Yes we can.\n",
              "When there was despair in the dust bowl and depression across the land, she saw a nation conquer fear itself with a New Deal, new jobs, a new sense of common purpose. Yes we can.\n",
              "When the bombs fell on our harbor and tyranny threatened the world, she was there to witness a generation rise to greatness and a democracy was saved. Yes we can.\n",
              "She was there for the buses in Montgomery, the hoses in Birmingham, a bridge in Selma, and a preacher from Atlanta who told a people that “We Shall Overcome.” Yes we can.\n",
              "A man touched down on the moon, a wall came down in Berlin, a world was connected by our own science and imagination.\n",
              "And this year, in this election, she touched her finger to a screen, and cast her vote, because after 106 years in America, through the best of times and the darkest of hours, she knows how America can change.\n",
              "Yes we can.\n",
              "America, we have come so far. We have seen so much. But there is so much more to do. So tonight, let us ask ourselves — if our children should live to see the next century; if my daughters should be so lucky to live as long as Ann Nixon Cooper, what change will they see? What progress will we have made?\n",
              "This is our chance to answer that call. This is our moment.\n",
              "This is our time, to put our people back to work and open doors of opportunity for our kids; to restore prosperity and promote the cause of peace; to reclaim the American dream and reaffirm that fundamental truth, that, out of many, we are one; that while we breathe, we hope. And where we are met with cynicism and doubts and those who tell us that we can’t, we will respond with that timeless creed that sums up the spirit of a people: Yes, we can.["
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2srygKeyZLn"
      },
      "source": [
        "### Playground\n",
        "\n",
        "La variable <i>doc</i> es un objeto de la clase <i>Doc</i> (https://spacy.io/api/doc)\n",
        "\n",
        "Visita la documentación de dicha clase y experimenta probando las diferentes funciones y atributos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMYPUEZAyZLn"
      },
      "outputs": [],
      "source": [
        "# Puedes insertar aquí código de pruebas para experimentar con las diferentes funciones y atributos de 'doc'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uV629hJyZLn"
      },
      "source": [
        "# Parte 2: preguntas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMXeDsK8yZLn"
      },
      "source": [
        "Para responder a cada una de las preguntas planteadas deberás aportar tanto el código fuente con el cual puedes conseguir la respuesta, como una explicación válida de la respuesta y de la forma de obtenerla."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVEwcQj4yZLn"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 1.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Cuántas palabras tiene el texto?</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zLDMOutNyZLn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d86d2079-fd65-4a9e-e023-e62f4fea6e0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The document contains 1732 words.\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "\n",
        "word_count = len([token for token in doc if not token.is_punct])\n",
        "\n",
        "print(f\"el documento contiene {word_count} palabras.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QvRw4kYyZLn"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spacy toma en cuenta los signos de puntuacion como una palabra por lo que si se desea conocer solo la cantidad de palabras se debería hacer un condicional para tomar en cuenta los tokens que no son signos de puntuación"
      ],
      "metadata": {
        "id": "E0pGIX-D0Zmw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6-ztzXUyZLo"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 2.</span>\n",
        "\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Cuántas oraciones tiene el texto?</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gdb71VzEyZLo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1c48c951-afe7-47bb-84e0-8a7b8d7fb9cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El documento contiene 83 oraciones.\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "\n",
        "# Contar el número de oraciones en el documento\n",
        "sentence_count = len(list(doc.sents))\n",
        "\n",
        "print(f\"El documento contiene {sentence_count} oraciones.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ln5t4w-zyZLo"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El atributo sents del objeto ```doc``` es un generador que devuelve las oraciones del documento. Al convertirlo en una lista usando ```list()```, podemos obtener el número de oraciones utilizando la función ```len()```."
      ],
      "metadata": {
        "id": "e1GOyTe61gfr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_q41Cc7yZLo"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 3.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Cuál el número de palabras de la oración más grande? ¿Cual es dicha oración?</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HoY7SxsXyZLo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "6c1481c0-5bd1-49d0-94f6-6236a50d1b5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La oración más larga es: It drew strength from the not-so-young people who braved the bitter cold and scorching heat to knock on doors of perfect strangers, and from the millions of Americans who volunteered and organized and proved that more than two centuries later a government of the people, by the people, and for the people has not perished from the Earth.\n",
            "\n",
            "Tiene 61 palabras.\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "\n",
        "\n",
        "# Encontrar la oración más larga\n",
        "longest_sentence = max(doc.sents, key=len)\n",
        "\n",
        "# Contar el número de palabras en la oración más larga\n",
        "word_count = len([token for token in longest_sentence if not token.is_punct])\n",
        "\n",
        "print(f\"La oración más larga es: {longest_sentence.text}\")\n",
        "print(f\"Tiene {word_count} palabras.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_LqUG8hyZLo"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*  Para encontrar la oración más larga, utilizamos ```max(doc.sents, key=len)```.\n",
        "* Esto itera sobre todas las oraciones del documento ```doc.sents``` y utiliza la función ```len()``` como clave para determinar la oración más larga.\n",
        "* Luego, contamos el número de palabras en la oración más larga utilizando una lista de comprensión.\n",
        "* Filtramos los tokens que no son signos para contar solo la cantidad de palabras.\n",
        "\n"
      ],
      "metadata": {
        "id": "x_KtRP_g2F2C"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipZtbbRTyZLo"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 4.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Cómo puedes obtener el lema, el sufijo y el análisis morfológico de cada token?</span>\n",
        "\n",
        "Recomendación: si no lo has hecho ya, visita la documentación de la clase <i>Token</i>: https://spacy.io/api/token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mknfQMBbyZLo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "11f2b67c-03f9-4376-dcab-6de728269226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oración de prueba : We are, and always will be, the United States of America.\n",
            "\n",
            "Token: We\n",
            "Lema: we\n",
            "Sufijo: We\n",
            "Análisis morfológico: Case=Nom|Number=Plur|Person=1|PronType=Prs\n",
            "---\n",
            "Token: are\n",
            "Lema: be\n",
            "Sufijo: are\n",
            "Análisis morfológico: Mood=Ind|Tense=Pres|VerbForm=Fin\n",
            "---\n",
            "Token: and\n",
            "Lema: and\n",
            "Sufijo: and\n",
            "Análisis morfológico: ConjType=Cmp\n",
            "---\n",
            "Token: always\n",
            "Lema: always\n",
            "Sufijo: ays\n",
            "Análisis morfológico: \n",
            "---\n",
            "Token: will\n",
            "Lema: will\n",
            "Sufijo: ill\n",
            "Análisis morfológico: VerbForm=Fin\n",
            "---\n",
            "Token: be\n",
            "Lema: be\n",
            "Sufijo: be\n",
            "Análisis morfológico: VerbForm=Inf\n",
            "---\n",
            "Token: the\n",
            "Lema: the\n",
            "Sufijo: the\n",
            "Análisis morfológico: Definite=Def|PronType=Art\n",
            "---\n",
            "Token: United\n",
            "Lema: United\n",
            "Sufijo: ted\n",
            "Análisis morfológico: Number=Sing\n",
            "---\n",
            "Token: States\n",
            "Lema: States\n",
            "Sufijo: tes\n",
            "Análisis morfológico: Number=Sing\n",
            "---\n",
            "Token: of\n",
            "Lema: of\n",
            "Sufijo: of\n",
            "Análisis morfológico: \n",
            "---\n",
            "Token: America\n",
            "Lema: America\n",
            "Sufijo: ica\n",
            "Análisis morfológico: Number=Sing\n",
            "---\n",
            "Token: \n",
            "\n",
            "Lema: \n",
            "\n",
            "Sufijo: \n",
            "\n",
            "Análisis morfológico: \n",
            "---\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "\n",
        "\n",
        "# Se toma una oración de ejemplo\n",
        "sentence_index = 5\n",
        "example_sentence = list(doc.sents)[sentence_index]\n",
        "\n",
        "print(f\"Oración de prueba : {example_sentence.text}\")\n",
        "\n",
        "for token in example_sentence:\n",
        "  if not token.is_punct:\n",
        "    print(f\"Token: {token.text}\")\n",
        "    print(f\"Lema: {token.lemma_}\")\n",
        "    print(f\"Sufijo: {token.suffix_}\")\n",
        "    print(f\"Análisis morfológico: {token.morph}\")\n",
        "    print(\"---\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn6tmJiByZLo"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El análisis morfológico del token, que proporciona detalles sobre las características gramaticales, como género, número, tiempo verbal, etc.\n",
        "\n",
        "Ejemplo:\n",
        "\n",
        "```\n",
        "  Token: be\n",
        "  Lema: be\n",
        "  Sufijo: be\n",
        "  Análisis morfológico: VerbForm=In\n",
        "```\n",
        "\n",
        "\n",
        "1. Token: America: Indica que el token analizado es la palabra \"America\".\n",
        "\n",
        "2.  Lema: America: El lema de un token es su forma base o de diccionario. En este caso, el lema de \"America\" es también \"America\". Esto sugiere que \"America\" está en su forma base y no tiene variaciones adicionales.\n",
        "\n",
        "3. Sufijo: ica: El sufijo es la parte final de la palabra. En este caso, el sufijo del token \"America\" es \"ica\". Esto indica que \"ica\" es la parte final de la palabra \"America\".\n",
        "\n",
        "4. Análisis morfológico: Number=Sing: El análisis morfológico proporciona información sobre las características gramaticales del token. En este caso, \"Number=Sing\" indica que el token \"America\" está en singular.\n",
        "\n",
        "    * Number representa la categoría gramatical de número.\n",
        "\n",
        "    * Sing es la abreviatura de \"singular\", lo que significa que el token \"America\" se refiere a una entidad singular."
      ],
      "metadata": {
        "id": "JJ4bcZML4sOj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEiYQCUyyZLo"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 5.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Cómo puedes identificar/eliminar las stop words?</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "uNWqeifhyZLo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8d0210ca-a11f-4996-85ee-c51089e5ae34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oración de prueba : It’s the answer that led those who’ve been told for so long by so many to be cynical and fearful and doubtful about what we can achieve to put their hands on the arc of history and bend it once more toward the hope of a better day.\n",
            "\n",
            "Token: It\n",
            "Is stop word: True\n",
            "---\n",
            "Token: ’s\n",
            "Is stop word: True\n",
            "---\n",
            "Token: the\n",
            "Is stop word: True\n",
            "---\n",
            "Token: answer\n",
            "Is stop word: False\n",
            "---\n",
            "Token: that\n",
            "Is stop word: True\n",
            "---\n",
            "Token: led\n",
            "Is stop word: False\n",
            "---\n",
            "Token: those\n",
            "Is stop word: True\n",
            "---\n",
            "Token: who\n",
            "Is stop word: True\n",
            "---\n",
            "Token: ’ve\n",
            "Is stop word: True\n",
            "---\n",
            "Token: been\n",
            "Is stop word: True\n",
            "---\n",
            "Token: told\n",
            "Is stop word: False\n",
            "---\n",
            "Token: for\n",
            "Is stop word: True\n",
            "---\n",
            "Token: so\n",
            "Is stop word: True\n",
            "---\n",
            "Token: long\n",
            "Is stop word: False\n",
            "---\n",
            "Token: by\n",
            "Is stop word: True\n",
            "---\n",
            "Token: so\n",
            "Is stop word: True\n",
            "---\n",
            "Token: many\n",
            "Is stop word: True\n",
            "---\n",
            "Token: to\n",
            "Is stop word: True\n",
            "---\n",
            "Token: be\n",
            "Is stop word: True\n",
            "---\n",
            "Token: cynical\n",
            "Is stop word: False\n",
            "---\n",
            "Token: and\n",
            "Is stop word: True\n",
            "---\n",
            "Token: fearful\n",
            "Is stop word: False\n",
            "---\n",
            "Token: and\n",
            "Is stop word: True\n",
            "---\n",
            "Token: doubtful\n",
            "Is stop word: False\n",
            "---\n",
            "Token: about\n",
            "Is stop word: True\n",
            "---\n",
            "Token: what\n",
            "Is stop word: True\n",
            "---\n",
            "Token: we\n",
            "Is stop word: True\n",
            "---\n",
            "Token: can\n",
            "Is stop word: True\n",
            "---\n",
            "Token: achieve\n",
            "Is stop word: False\n",
            "---\n",
            "Token: to\n",
            "Is stop word: True\n",
            "---\n",
            "Token: put\n",
            "Is stop word: True\n",
            "---\n",
            "Token: their\n",
            "Is stop word: True\n",
            "---\n",
            "Token: hands\n",
            "Is stop word: False\n",
            "---\n",
            "Token: on\n",
            "Is stop word: True\n",
            "---\n",
            "Token: the\n",
            "Is stop word: True\n",
            "---\n",
            "Token: arc\n",
            "Is stop word: False\n",
            "---\n",
            "Token: of\n",
            "Is stop word: True\n",
            "---\n",
            "Token: history\n",
            "Is stop word: False\n",
            "---\n",
            "Token: and\n",
            "Is stop word: True\n",
            "---\n",
            "Token: bend\n",
            "Is stop word: False\n",
            "---\n",
            "Token: it\n",
            "Is stop word: True\n",
            "---\n",
            "Token: once\n",
            "Is stop word: True\n",
            "---\n",
            "Token: more\n",
            "Is stop word: True\n",
            "---\n",
            "Token: toward\n",
            "Is stop word: True\n",
            "---\n",
            "Token: the\n",
            "Is stop word: True\n",
            "---\n",
            "Token: hope\n",
            "Is stop word: False\n",
            "---\n",
            "Token: of\n",
            "Is stop word: True\n",
            "---\n",
            "Token: a\n",
            "Is stop word: True\n",
            "---\n",
            "Token: better\n",
            "Is stop word: False\n",
            "---\n",
            "Token: day\n",
            "Is stop word: False\n",
            "---\n",
            "Token: \n",
            "\n",
            "Is stop word: False\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "\n",
        "\n",
        "# Se toma una oración de ejemplo\n",
        "sentence_index = 6\n",
        "example_sentence = list(doc.sents)[sentence_index]\n",
        "\n",
        "print(f\"Oración de prueba : {example_sentence.text}\")\n",
        "for token in example_sentence:\n",
        "  if not token.is_punct:\n",
        "    print(f\"Token: {token.text}\")\n",
        "    print(f\"Is stop word: {token.is_stop}\")\n",
        "    print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zchKd7iwyZLo"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las stop words, o palabras vacías, son palabras comunes en un idioma que generalmente se consideran poco informativas para el análisis de texto. Ejemplos en español incluyen artículos, preposiciones, pronombres y conjunciones.\n",
        "\n",
        "La eliminación de stop words es una técnica común en el procesamiento del lenguaje natural para reducir la dimensionalidad del texto y enfocarse en las palabras más significativas. Esto puede mejorar la eficiencia y precisión en tareas como búsqueda, clasificación y análisis de sentimientos.\n",
        "\n",
        "Sin embargo, eliminar stop words también puede afectar la estructura y el contexto del texto. Por lo tanto, la decisión de eliminarlas depende del objetivo específico del análisis y su impacto en los resultados deseados."
      ],
      "metadata": {
        "id": "JQo2VTQt6nkD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeC9i2eayZLp"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 6.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Qué atributo del token contiene la etiqueta NER?</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "4lFTyry_yZLp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e020d903-b9e3-4e76-c7c9-c9a11d2e51d1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">For even as we celebrate \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    tonight\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
              "</mark>\n",
              ", we know the challenges that \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    tomorrow\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " will bring are the greatest of our lifetime — \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    two\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " wars, a planet in peril, the worst financial crisis in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    a century\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ".<br></div></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from spacy import displacy\n",
        "\n",
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "\n",
        "sentence_index = 18\n",
        "example_sentence = list(doc.sents)[sentence_index]\n",
        "\n",
        "displacy.render(example_sentence, style=\"ent\", jupyter=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_gO0mdXyZLp"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvIG5d9zyZLp"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 7.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Qué entidades nombradas soporta Spacy?, ¿Qué significa cada una?</span>\n",
        "\n",
        "<b>Nota</b>: Debes escribir el código que liste las entidades disponibles y la explicación de las mismas. El listado sin código se considerará respuesta incompleta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "1aVUd-NkyZLp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e91cd9e2-84fa-403d-cb7a-3929e97a3dae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Etiquetas NER soportadas por spaCy:\n",
            "CARDINAL\n",
            "DATE\n",
            "EVENT\n",
            "FAC\n",
            "GPE\n",
            "LANGUAGE\n",
            "LAW\n",
            "LOC\n",
            "MONEY\n",
            "NORP\n",
            "ORDINAL\n",
            "ORG\n",
            "PERCENT\n",
            "PERSON\n",
            "PRODUCT\n",
            "QUANTITY\n",
            "TIME\n",
            "WORK_OF_ART\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "# Obtener las etiquetas NER disponibles en el modelo\n",
        "labels = nlp.get_pipe(\"ner\").labels\n",
        "print(\"Etiquetas NER soportadas por spaCy:\")\n",
        "for label in labels:\n",
        "    print(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qak2ZpnRyZLp"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NER (Named Entity Recognition) es una tarea fundamental en el procesamiento del lenguaje natural que consiste en identificar y clasificar las entidades nombradas en un texto. Las entidades nombradas son palabras o frases que se refieren a objetos, personas, lugares, organizaciones u otros conceptos específicos.\n",
        "\n",
        "En spaCy, el componente NER se encarga de asignar etiquetas a las entidades nombradas encontradas en el texto. a continuación las  etiquetas que incluye el modelo ```en_core_web_sm```:\n",
        "\n",
        "\n",
        "1. `CARDINAL`: Representa números cardinales, como \"uno\", \"dos\", \"tres\", etc.\n",
        "2. `DATE`: Representa fechas, como \"2023-06-08\", \"el próximo lunes\", \"en enero\", etc.\n",
        "3. `EVENT`: Representa eventos nombrados, como \"la Segunda Guerra Mundial\", \"el Festival de Cannes\", etc.\n",
        "4. `FAC`: Representa instalaciones y edificios, como \"el Empire State Building\", \"el Museo del Louvre\", etc.\n",
        "5. `GPE`: Representa entidades geopolíticas, como países, estados, ciudades, etc.\n",
        "6. `LANGUAGE`: Representa nombres de idiomas, como \"español\", \"inglés\", \"francés\", etc.\n",
        "7. `LAW`: Representa documentos legales y leyes, como \"la Constitución\", \"el Código Penal\", etc.\n",
        "8. `LOC`: Representa ubicaciones geográficas, como \"el río Amazonas\", \"el desierto del Sahara\", etc.\n",
        "9. `MONEY`: Representa cantidades monetarias, como \"100 dólares\", \"25 euros\", etc.\n",
        "10. `NORP`: Representa nacionalidades, religiones, grupos políticos, etc., como \"estadounidense\", \"católico\", \"demócrata\", etc.\n",
        "11. `ORDINAL`: Representa números ordinales, como \"primero\", \"segundo\", \"tercero\", etc.\n",
        "12. `ORG`: Representa organizaciones, empresas, instituciones, agencias gubernamentales, etc.\n",
        "13. `PERCENT`: Representa porcentajes, como \"50%\", \"el 75 por ciento\", etc.\n",
        "14. `PERSON`: Representa nombres de personas, incluyendo nombres completos, nombres de pila y apellidos.\n",
        "15. `PRODUCT`: Representa nombres de productos, como \"iPhone\", \"Coca-Cola\", \"Toyota Corolla\", etc.\n",
        "16. `QUANTITY`: Representa cantidades y unidades de medida, como \"10 kilómetros\", \"5 litros\", etc.\n",
        "17. `TIME`: Representa horas y duraciones, como \"10:30 AM\", \"dos horas\", \"30 minutos\", etc.\n",
        "18. `WORK_OF_ART`: Representa títulos de obras de arte, como libros, películas, canciones, etc.\n"
      ],
      "metadata": {
        "id": "nMjOCK-P9Fo-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4nE55w1yZLp"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 8.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Qué entidades nombradas diferentes son reconocidas en el texto?, ¿cuántas hay de cada tipo?</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "pfjLjsCXyZLp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "75a90fb5-ade1-4d17-9721-cb3ca57dbaeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entidades nombradas reconocidas:\n",
            "GPE: 24\n",
            "TIME: 16\n",
            "ORDINAL: 2\n",
            "NORP: 12\n",
            "MONEY: 1\n",
            "CARDINAL: 8\n",
            "DATE: 12\n",
            "LOC: 2\n",
            "FAC: 1\n",
            "ORG: 5\n",
            "PERSON: 2\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "\n",
        "entity_counts = {}\n",
        "for ent in doc.ents:\n",
        "    if ent.label_ not in entity_counts:\n",
        "        entity_counts[ent.label_] = 1\n",
        "    else:\n",
        "        entity_counts[ent.label_] += 1\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(\"Entidades nombradas reconocidas:\")\n",
        "for entity_type, count in entity_counts.items():\n",
        "    print(f\"{entity_type}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jrw480-GyZLp"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iteramos sobre las entidades nombradas reconocidas en el documento utilizando doc.ents.\n",
        "Para cada entidad nombrada (ent), verificamos si su etiqueta (ent.label_) ya existe como clave en el diccionario entity_counts:\n",
        "\n",
        "* Si la etiqueta no existe, la agregamos al diccionario con un valor inicial de 1.\n",
        "* Si la etiqueta ya existe, incrementamos su valor en 1."
      ],
      "metadata": {
        "id": "3KxtKXa7-YAf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD0t3c2KyZLp"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 9.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Explica con tus palabras qué es el código IOB para el reconocimiento de entiedades. Pon un ejemplo, sacado del texto, de una etiqueta de un único token y una etiqueta compuesta por varios tokens.</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "bhXp4kXHyZLp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8d8c9565-a698-4b7e-a95a-bdbf52a4b521"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(millions, one, Ann Nixon Cooper, 106 years old)\n",
            "Token: millions, B, CARDINAL\n",
            "---\n",
            "Token: one, B, CARDINAL\n",
            "---\n",
            "Token: Ann, B, PERSON\n",
            "---\n",
            "Token: Nixon, I, PERSON\n",
            "---\n",
            "Token: Cooper, I, PERSON\n",
            "---\n",
            "Token: 106, B, DATE\n",
            "---\n",
            "Token: years, I, DATE\n",
            "---\n",
            "Token: old, I, DATE\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "\n",
        "\n",
        "one_token_example_sentence = 'She’s a lot like the millions of others who stood in line to make their voice heard in this election except for one thing: Ann Nixon Cooper is 106 years old.'\n",
        "\n",
        "doc = nlp(one_token_example_sentence)\n",
        "\n",
        "print(doc.ents)\n",
        "\n",
        "for x in range(len(doc)):\n",
        "  if doc[x].ent_iob_ != \"O\":\n",
        "    print(f\"Token: {doc[x]}, {doc[x].ent_iob_}, {doc[x].ent_type_}\")\n",
        "    print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTuujMSqyZLq"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El código IOB (Inside-Outside-Beginning) es una convención utilizada en el reconocimiento de entidades nombradas (NER) para indicar la posición y el tipo de cada token dentro de una entidad. El código IOB ayuda a identificar si un token es parte de una entidad y, en caso afirmativo, si es el comienzo (B) o la continuación (I) de la entidad. Los tokens que no forman parte de ninguna entidad se etiquetan como \"O\" (Outside).\n",
        "La estructura del código IOB es la siguiente:\n",
        "\n",
        "\"B-\" se utiliza para etiquetar el primer token de una entidad.\n",
        "\"I-\" se utiliza para etiquetar los tokens subsiguientes dentro de la misma entidad.\n",
        "\"O\" se utiliza para etiquetar los tokens que no pertenecen a ninguna entidad"
      ],
      "metadata": {
        "id": "q12thsW3Qwxb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C9EET72yZLq"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 10.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Qué POS Tags aparecen en el texto, y cuántos hay tokens hay de cada uno?</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "vfDVuSpHyZLq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "04064253-9ee7-4d12-c020-ee475148f8ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS Tags encontrados en el texto:\n",
            "PUNCT: 205\n",
            "PROPN: 56\n",
            "SPACE: 46\n",
            "SCONJ: 51\n",
            "PRON: 243\n",
            "VERB: 211\n",
            "ADV: 63\n",
            "AUX: 125\n",
            "DET: 153\n",
            "NOUN: 330\n",
            "ADJ: 93\n",
            "ADP: 189\n",
            "CCONJ: 92\n",
            "NUM: 18\n",
            "PART: 53\n",
            "SYM: 3\n",
            "INTJ: 7\n",
            "X: 1\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "\n",
        "file_name = \"/content/drive/MyDrive/Colab Notebooks/barack-obama-speech.txt\"\n",
        "doc = nlp(pathlib.Path(file_name).read_text(encoding=\"utf-8\"))\n",
        "\n",
        "# Contar los POS Tags\n",
        "pos_counts = {}\n",
        "for token in doc:\n",
        "    if token.pos_ not in pos_counts:\n",
        "        pos_counts[token.pos_] = 1\n",
        "    else:\n",
        "        pos_counts[token.pos_] += 1\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(\"POS Tags encontrados en el texto:\")\n",
        "for pos, count in pos_counts.items():\n",
        "    print(f\"{pos}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMZleCRLyZLq"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los POS Tags (Part-of-Speech Tags) son etiquetas que indican la categoría gramatical de cada palabra en un texto. Estas etiquetas proporcionan información sobre la función sintáctica y morfológica de las palabras, lo que es fundamental para el análisis lingüístico y el procesamiento del lenguaje natural.\n",
        "\n",
        "\n",
        "Los POS Tags son asignados automáticamente por herramientas de procesamiento de lenguaje natural, utilizando modelos de lenguaje entrenados en grandes corpus anotados. Estos modelos aprenden patrones y reglas para determinar la categoría gramatical más probable de cada palabra en función de su contexto.\n",
        "\n",
        "El etiquetado POS es un paso fundamental en muchas tareas de procesamiento del lenguaje natural, como el análisis sintáctico, la desambiguación del sentido de las palabras, la extracción de información y la traducción automática, entre otras. Proporciona una base para comprender la estructura y el significado de las oraciones en un texto.\n",
        "\n",
        "Descripción de etiquetas encontradas:\n",
        "\n",
        "1. **PUNCT** (Puntuación): Signos de puntuación como puntos, comas, signos de interrogación, etc.\n",
        "   - Ejemplo: \".\", \",\", \"!\", \"?\"\n",
        "\n",
        "2. **PROPN** (Nombre Propio): Nombres de personas, lugares, organizaciones específicas, etc.\n",
        "   - Ejemplo: \"Juan\", \"Nueva York\", \"Apple Inc.\"\n",
        "\n",
        "3. **SPACE** (Espacio): Caracteres de espacio en blanco como espacios, tabulaciones y saltos de línea.\n",
        "\n",
        "4. **SCONJ** (Conjunción Subordinante): Palabras que introducen cláusulas subordinadas.\n",
        "   - Ejemplo: \"porque\", \"aunque\", \"si\", \"cuando\"\n",
        "\n",
        "5. **PRON** (Pronombre): Palabras que sustituyen a un sustantivo.\n",
        "   - Ejemplo: \"él\", \"ella\", \"ellos\", \"lo\", \"me\"\n",
        "\n",
        "6. **VERB** (Verbo): Palabras que indican acciones, estados o procesos.\n",
        "   - Ejemplo: \"correr\", \"es\", \"fueron\", \"había\"\n",
        "\n",
        "7. **ADV** (Adverbio): Palabras que modifican verbos, adjetivos u otros adverbios.\n",
        "   - Ejemplo: \"rápidamente\", \"muy\", \"aquí\", \"ayer\"\n",
        "\n",
        "8. **AUX** (Verbo Auxiliar): Verbos que acompañan a otros verbos para indicar tiempo, aspecto, modo, etc.\n",
        "   - Ejemplo: \"haber\", \"ser\", \"estar\"\n",
        "\n",
        "9. **DET** (Determinante): Palabras que preceden y modifican sustantivos, como artículos y demostrativos.\n",
        "   - Ejemplo: \"el\", \"la\", \"un\", \"este\", \"esos\"\n",
        "\n",
        "10. **NOUN** (Sustantivo): Palabras que representan personas, lugares, cosas o conceptos.\n",
        "    - Ejemplo: \"libro\", \"casa\", \"felicidad\"\n",
        "\n",
        "11. **ADJ** (Adjetivo): Palabras que describen o modifican sustantivos.\n",
        "    - Ejemplo: \"rojo\", \"grande\", \"interesante\"\n",
        "\n",
        "12. **ADP** (Adposición): Palabras que indican relaciones gramaticales, como preposiciones y posposiciones.\n",
        "    - Ejemplo: \"a\", \"de\", \"en\", \"por\"\n",
        "\n",
        "13. **CCONJ** (Conjunción Coordinante): Palabras que conectan palabras, frases o cláusulas del mismo nivel sintáctico.\n",
        "    - Ejemplo: \"y\", \"o\", \"pero\", \"sino\"\n",
        "\n",
        "14. **NUM** (Numeral): Palabras que representan números.\n",
        "    - Ejemplo: \"uno\", \"dos\", \"10\", \"primer\"\n",
        "\n",
        "15. **PART** (Partícula): Palabras que desempeñan funciones gramaticales específicas.\n",
        "    - Ejemplo: \"no\" (negación), \"sí\" (afirmación)\n",
        "\n",
        "16. **SYM** (Símbolo): Símbolos y caracteres especiales.\n",
        "    - Ejemplo: \"%\", \"$\", \"+\"\n",
        "\n",
        "17. **INTJ** (Interjección): Palabras que expresan emociones o sentimientos repentinos.\n",
        "    - Ejemplo: \"oh\", \"wow\", \"ouch\"\n",
        "\n",
        "18. **X** (Otro): Palabras que no encajan en ninguna de las categorías anteriores o son desconocidas.\n"
      ],
      "metadata": {
        "id": "7X-X9d-BRsr_"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}